{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import spacy\n",
    "import re, logging, warnings\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from pprint import pprint\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pd.read_csv(\"../data/show_text_combined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>show_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can it be the breeze that fills the trees  Wit...</td>\n",
       "      <td>'Allo 'Allo!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'd like to marry a girl that's skinny. I thin...</td>\n",
       "      <td>'Til Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It's that dream again. Just who is that guy? W...</td>\n",
       "      <td>07 Ghost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 You all might have top-class credentials fro...</td>\n",
       "      <td>1,000 Places To See Before You Die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1  Welcome to 10 O'Clock Live. It's Wednesday ...</td>\n",
       "      <td>10 O'Clock Live</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Can it be the breeze that fills the trees  Wit...   \n",
       "1  I'd like to marry a girl that's skinny. I thin...   \n",
       "2  It's that dream again. Just who is that guy? W...   \n",
       "3  1 You all might have top-class credentials fro...   \n",
       "4  1  Welcome to 10 O'Clock Live. It's Wednesday ...   \n",
       "\n",
       "                           show_names  \n",
       "0                        'Allo 'Allo!  \n",
       "1                          'Til Death  \n",
       "2                            07 Ghost  \n",
       "3  1,000 Places To See Before You Die  \n",
       "4                     10 O'Clock Live  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test LDA Run with subset of data\n",
    "borrowed liberally from https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = text.sample(frac=.005, random_state=412)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>show_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2735</th>\n",
       "      <td>[SWITCHBOARD BUZZES.] Paul Drake Detective Age...</td>\n",
       "      <td>Perry Mason</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592</th>\n",
       "      <td>- Hi, is this Lina Warbler? - Yes. This is Eth...</td>\n",
       "      <td>The Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "      <td>1 We're setting off on a ten-week journey, cyc...</td>\n",
       "      <td>On Hannibal's Trail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4408</th>\n",
       "      <td>[Ringing servant's entrance bell.]  Well?  Mrs...</td>\n",
       "      <td>Upstairs, Downstairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>NARRATOR: In a few minutes, this woman will be...</td>\n",
       "      <td>Ellery Queen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text            show_names\n",
       "2735  [SWITCHBOARD BUZZES.] Paul Drake Detective Age...           Perry Mason\n",
       "3592  - Hi, is this Lina Warbler? - Yes. This is Eth...             The Class\n",
       "2622  1 We're setting off on a ten-week journey, cyc...   On Hannibal's Trail\n",
       "4408  [Ringing servant's entrance bell.]  Well?  Mrs...  Upstairs, Downstairs\n",
       "1176  NARRATOR: In a few minutes, this woman will be...          Ellery Queen"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load in Stop Words from SpaCy and nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparing stop words from spacy and nltk\n",
    "nlp = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_stop_words = nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spacy_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_stop_words = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['move',\n",
       " 'name',\n",
       " 'towards',\n",
       " 'else',\n",
       " 'unless',\n",
       " 'sometimes',\n",
       " 'regarding',\n",
       " 'therefore',\n",
       " \"'ve\",\n",
       " 'meanwhile',\n",
       " 'besides',\n",
       " 'beforehand',\n",
       " 'nothing',\n",
       " 'give',\n",
       " 'often',\n",
       " 'seem',\n",
       " 'across',\n",
       " 'nobody',\n",
       " 'part',\n",
       " 'within',\n",
       " 'hereafter',\n",
       " 'serious',\n",
       " 'toward',\n",
       " 'take',\n",
       " '’ve',\n",
       " 'everything',\n",
       " 'amount',\n",
       " 'none',\n",
       " 'seems',\n",
       " 'something',\n",
       " 'since',\n",
       " 'side',\n",
       " \"'re\",\n",
       " 'rather',\n",
       " '‘ll',\n",
       " '’m',\n",
       " 'per',\n",
       " 'anywhere',\n",
       " 'anything',\n",
       " 'almost',\n",
       " 'among',\n",
       " 'seemed',\n",
       " 'however',\n",
       " 'fifty',\n",
       " 'whereafter',\n",
       " 'whoever',\n",
       " 'please',\n",
       " 'indeed',\n",
       " 'mostly',\n",
       " 'whatever',\n",
       " 'hereupon',\n",
       " 'seeming',\n",
       " '’d',\n",
       " 'wherever',\n",
       " 'beyond',\n",
       " 'around',\n",
       " 'formerly',\n",
       " 'really',\n",
       " 'even',\n",
       " 'may',\n",
       " 'one',\n",
       " 'whether',\n",
       " 'thru',\n",
       " 'whereas',\n",
       " 'hence',\n",
       " 'somehow',\n",
       " 'perhaps',\n",
       " 'former',\n",
       " 'front',\n",
       " 'along',\n",
       " 'without',\n",
       " 'therein',\n",
       " 'nevertheless',\n",
       " '’re',\n",
       " 'noone',\n",
       " 'nowhere',\n",
       " 'everywhere',\n",
       " '’ll',\n",
       " 'whence',\n",
       " 'cannot',\n",
       " 'us',\n",
       " 'though',\n",
       " 'someone',\n",
       " 'upon',\n",
       " 'less',\n",
       " 'thereafter',\n",
       " 'could',\n",
       " 'everyone',\n",
       " 'twelve',\n",
       " 'used',\n",
       " 'behind',\n",
       " 'namely',\n",
       " \"'ll\",\n",
       " 'still',\n",
       " 'whole',\n",
       " 'throughout',\n",
       " 'hundred',\n",
       " 'two',\n",
       " 'many',\n",
       " 'eleven',\n",
       " 'go',\n",
       " 'becomes',\n",
       " 'others',\n",
       " 'sixty',\n",
       " 'via',\n",
       " 'neither',\n",
       " 'might',\n",
       " 'much',\n",
       " 'every',\n",
       " 'well',\n",
       " 'except',\n",
       " 'back',\n",
       " 'whereby',\n",
       " '‘ve',\n",
       " 'moreover',\n",
       " 'yet',\n",
       " 'see',\n",
       " 'elsewhere',\n",
       " 'third',\n",
       " 'various',\n",
       " 'ever',\n",
       " \"n't\",\n",
       " 'full',\n",
       " 'keep',\n",
       " 'became',\n",
       " 'would',\n",
       " \"'d\",\n",
       " 'several',\n",
       " 'whose',\n",
       " 'herein',\n",
       " 'beside',\n",
       " 'wherein',\n",
       " 'whenever',\n",
       " 'whereupon',\n",
       " 'alone',\n",
       " 'say',\n",
       " '‘d',\n",
       " 'first',\n",
       " 'amongst',\n",
       " 'sometime',\n",
       " 'last',\n",
       " 'three',\n",
       " 'five',\n",
       " 'ten',\n",
       " 'call',\n",
       " 'hereby',\n",
       " 'thereby',\n",
       " '’s',\n",
       " 'quite',\n",
       " 'thereupon',\n",
       " 'already',\n",
       " 'n’t',\n",
       " '‘m',\n",
       " 'top',\n",
       " 'also',\n",
       " 'although',\n",
       " 'forty',\n",
       " 'six',\n",
       " 'bottom',\n",
       " 'twenty',\n",
       " 'next',\n",
       " 'onto',\n",
       " 'become',\n",
       " 'whither',\n",
       " 'latterly',\n",
       " 'n‘t',\n",
       " 'empty',\n",
       " \"'s\",\n",
       " 'becoming',\n",
       " \"'m\",\n",
       " 'done',\n",
       " 'show',\n",
       " 'otherwise',\n",
       " 'thence',\n",
       " '‘re',\n",
       " 'another',\n",
       " 'made',\n",
       " 'always',\n",
       " 'afterwards',\n",
       " '‘s',\n",
       " 'get',\n",
       " 'never',\n",
       " 'together',\n",
       " 'must',\n",
       " 'mine',\n",
       " 'eight',\n",
       " 'put',\n",
       " 'nine',\n",
       " 'make',\n",
       " 'anyway',\n",
       " 'ca',\n",
       " 'enough',\n",
       " 'least',\n",
       " 'anyhow',\n",
       " 'using',\n",
       " 'fifteen',\n",
       " 'due',\n",
       " 'thus',\n",
       " 'anyone',\n",
       " 'either',\n",
       " 'somewhere',\n",
       " 'latter',\n",
       " 'four']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_words = []\n",
    "for word in spacy_stop_words:\n",
    "    if word not in nltk_stop_words:\n",
    "        diff_words.append(word)\n",
    "diff_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are more words in the spacy stop words list will try that one first then will try the nltk list\n",
    "#### And now time to tokenize the text\n",
    "setting deacc=True in order to remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    for word in text:\n",
    "        yield(gensim.utils.simple_preprocess(str(word), deacc=True))\n",
    "\n",
    "test_df[\"text_tokenized\"] = list(tokenizer(test_df[\"text\"]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>show_names</th>\n",
       "      <th>text_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2735</th>\n",
       "      <td>[SWITCHBOARD BUZZES.] Paul Drake Detective Age...</td>\n",
       "      <td>Perry Mason</td>\n",
       "      <td>[switchboard, buzzes, paul, drake, detective, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592</th>\n",
       "      <td>- Hi, is this Lina Warbler? - Yes. This is Eth...</td>\n",
       "      <td>The Class</td>\n",
       "      <td>[hi, is, this, lina, warbler, yes, this, is, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "      <td>1 We're setting off on a ten-week journey, cyc...</td>\n",
       "      <td>On Hannibal's Trail</td>\n",
       "      <td>[we, re, setting, off, on, ten, week, journey,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4408</th>\n",
       "      <td>[Ringing servant's entrance bell.]  Well?  Mrs...</td>\n",
       "      <td>Upstairs, Downstairs</td>\n",
       "      <td>[ringing, servant, entrance, bell, well, mrs, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>NARRATOR: In a few minutes, this woman will be...</td>\n",
       "      <td>Ellery Queen</td>\n",
       "      <td>[narrator, in, few, minutes, this, woman, will...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text            show_names  \\\n",
       "2735  [SWITCHBOARD BUZZES.] Paul Drake Detective Age...           Perry Mason   \n",
       "3592  - Hi, is this Lina Warbler? - Yes. This is Eth...             The Class   \n",
       "2622  1 We're setting off on a ten-week journey, cyc...   On Hannibal's Trail   \n",
       "4408  [Ringing servant's entrance bell.]  Well?  Mrs...  Upstairs, Downstairs   \n",
       "1176  NARRATOR: In a few minutes, this woman will be...          Ellery Queen   \n",
       "\n",
       "                                         text_tokenized  \n",
       "2735  [switchboard, buzzes, paul, drake, detective, ...  \n",
       "3592  [hi, is, this, lina, warbler, yes, this, is, e...  \n",
       "2622  [we, re, setting, off, on, ten, week, journey,...  \n",
       "4408  [ringing, servant, entrance, bell, well, mrs, ...  \n",
       "1176  [narrator, in, few, minutes, this, woman, will...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create bigrams and trigram models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = gensim.models.Phrases(test_df[\"text_tokenized\"], min_count=10, threshold=500)\n",
    "#trigrams are madde by applying the same method to the bigram output that made the bigrams from the te\n",
    "trigram = gensim.models.Phrases(bigram[test_df[\"text_tokenized\"]], threshold=500)\n",
    "\n",
    "bigram_model = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_model = gensim.models.phrases.Phraser(trigram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define functions to remove stopwords, make bigrams, trigrams, then lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in spacy_stop_words] for doc in text]\n",
    "\n",
    "def make_bigrams(text):\n",
    "    return [bigram_model[doc] for doc in text]\n",
    "\n",
    "def make_trigrams(text):\n",
    "    return [trigram_model[bigram_mod[doc]] for doc in text]\n",
    "\n",
    "def lemmatization(text, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    text_out = []\n",
    "    for sent in text:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        text_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return text_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_no_stopwords = remove_stopwords(test_df[\"text_tokenized\"])\n",
    "#test_df[\"text_no_stopwords\"] = remove_stopwords(test_df[\"text_tokenized\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_bigrams = make_bigrams(text_no_stopwords)\n",
    "#test_df[\"text_bigrams\"] = make_bigrams(test_df[\"text_no_stopwords\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "nlp.max_length = 2_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"text_lemmatized\"] = lemmatization(text_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "#options for lemmatization , allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_words(col):\n",
    "    word_count = 0\n",
    "    for row in col:\n",
    "        word_count += len(row)\n",
    "    return word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1211705"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_words(text_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>show_names</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2735</th>\n",
       "      <td>[SWITCHBOARD BUZZES.] Paul Drake Detective Age...</td>\n",
       "      <td>Perry Mason</td>\n",
       "      <td>[switchboard, buzzes, paul, drake, detective, ...</td>\n",
       "      <td>[buzz, want, night, number, sure, reach, wait,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592</th>\n",
       "      <td>- Hi, is this Lina Warbler? - Yes. This is Eth...</td>\n",
       "      <td>The Class</td>\n",
       "      <td>[hi, is, this, lina, warbler, yes, this, is, e...</td>\n",
       "      <td>[remember, brown, hair, kind, funny, sort, mid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "      <td>1 We're setting off on a ten-week journey, cyc...</td>\n",
       "      <td>On Hannibal's Trail</td>\n",
       "      <td>[we, re, setting, off, on, ten, week, journey,...</td>\n",
       "      <td>[set, week, trail, great, carthaginian, warrio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4408</th>\n",
       "      <td>[Ringing servant's entrance bell.]  Well?  Mrs...</td>\n",
       "      <td>Upstairs, Downstairs</td>\n",
       "      <td>[ringing, servant, entrance, bell, well, mrs, ...</td>\n",
       "      <td>[ring, servant, send, come, position, parlorma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>NARRATOR: In a few minutes, this woman will be...</td>\n",
       "      <td>Ellery Queen</td>\n",
       "      <td>[narrator, in, few, minutes, this, woman, will...</td>\n",
       "      <td>[woman, dead, question, kill, philander, finan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text            show_names  \\\n",
       "2735  [SWITCHBOARD BUZZES.] Paul Drake Detective Age...           Perry Mason   \n",
       "3592  - Hi, is this Lina Warbler? - Yes. This is Eth...             The Class   \n",
       "2622  1 We're setting off on a ten-week journey, cyc...   On Hannibal's Trail   \n",
       "4408  [Ringing servant's entrance bell.]  Well?  Mrs...  Upstairs, Downstairs   \n",
       "1176  NARRATOR: In a few minutes, this woman will be...          Ellery Queen   \n",
       "\n",
       "                                         text_tokenized  \\\n",
       "2735  [switchboard, buzzes, paul, drake, detective, ...   \n",
       "3592  [hi, is, this, lina, warbler, yes, this, is, e...   \n",
       "2622  [we, re, setting, off, on, ten, week, journey,...   \n",
       "4408  [ringing, servant, entrance, bell, well, mrs, ...   \n",
       "1176  [narrator, in, few, minutes, this, woman, will...   \n",
       "\n",
       "                                        text_lemmatized  \n",
       "2735  [buzz, want, night, number, sure, reach, wait,...  \n",
       "3592  [remember, brown, hair, kind, funny, sort, mid...  \n",
       "2622  [set, week, trail, great, carthaginian, warrio...  \n",
       "4408  [ring, servant, send, come, position, parlorma...  \n",
       "1176  [woman, dead, question, kill, philander, finan...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary\n",
    "id2word = corpora.Dictionary(test_df[\"text_lemmatized\"])\n",
    "\n",
    "#the lemmatized text\n",
    "texts = test_df[\"text_lemmatized\"]\n",
    "\n",
    "#term doc frequency (corpus)\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('-PRON-', 3),\n",
       "  ('aahhh', 1),\n",
       "  ('ab', 3),\n",
       "  ('abandon', 10),\n",
       "  ('abbey', 4),\n",
       "  ('aberration', 1),\n",
       "  ('abet', 2),\n",
       "  ('abeyance', 1),\n",
       "  ('abhor', 1),\n",
       "  ('ability', 13),\n",
       "  ('able', 136),\n",
       "  ('abnormal', 2),\n",
       "  ('abnormality', 2),\n",
       "  ('aboard', 1),\n",
       "  ('abouthiscar', 1),\n",
       "  ('abrasion', 2),\n",
       "  ('abruptly', 2),\n",
       "  ('abscond', 1),\n",
       "  ('absence', 4),\n",
       "  ('absentminde', 1),\n",
       "  ('absolute', 14),\n",
       "  ('absolutely', 106),\n",
       "  ('absurd', 7),\n",
       "  ('abundantly', 1),\n",
       "  ('abuse', 2),\n",
       "  ('abusive', 4),\n",
       "  ('academic', 1),\n",
       "  ('accelerate', 1),\n",
       "  ('acceleration', 1),\n",
       "  ('accelerator', 1),\n",
       "  ('accent', 15),\n",
       "  ('accept', 44),\n",
       "  ('acceptable', 1),\n",
       "  ('access', 12),\n",
       "  ('accessible', 1),\n",
       "  ('accessory', 9),\n",
       "  ('accident', 132),\n",
       "  ('accidental', 8),\n",
       "  ('accidentally', 13),\n",
       "  ('accommodate', 6),\n",
       "  ('accommodating', 1),\n",
       "  ('accommodation', 2),\n",
       "  ('accompany', 7),\n",
       "  ('accomplice', 15),\n",
       "  ('accomplish', 7),\n",
       "  ('accomplished', 2),\n",
       "  ('accomplishment', 1),\n",
       "  ('accord', 76),\n",
       "  ('accordance', 1),\n",
       "  ('accordingly', 5),\n",
       "  ('accost', 2),\n",
       "  ('account', 102),\n",
       "  ('accountant', 7),\n",
       "  ('accounting', 5),\n",
       "  ('accredit', 2),\n",
       "  ('accumulate', 1),\n",
       "  ('accuracy', 1),\n",
       "  ('accurate', 8),\n",
       "  ('accurately', 3),\n",
       "  ('accusation', 12),\n",
       "  ('accuse', 64),\n",
       "  ('accuser', 1),\n",
       "  ('accustom', 2),\n",
       "  ('accustomed', 1),\n",
       "  ('ace', 2),\n",
       "  ('ache', 2),\n",
       "  ('achieve', 1),\n",
       "  ('achievement', 1),\n",
       "  ('acid', 7),\n",
       "  ('acknowledge', 1),\n",
       "  ('acknowledgement', 1),\n",
       "  ('aclient', 1),\n",
       "  ('acme', 1),\n",
       "  ('acoustic', 1),\n",
       "  ('acquaint', 25),\n",
       "  ('acquaintance', 5),\n",
       "  ('acquainted', 1),\n",
       "  ('acquire', 8),\n",
       "  ('acquisition', 4),\n",
       "  ('acquit', 12),\n",
       "  ('acquittal', 3),\n",
       "  ('acre', 16),\n",
       "  ('acreage', 7),\n",
       "  ('act', 93),\n",
       "  ('acting', 2),\n",
       "  ('action', 61),\n",
       "  ('active', 4),\n",
       "  ('actively', 1),\n",
       "  ('activity', 15),\n",
       "  ('actor', 4),\n",
       "  ('actress', 10),\n",
       "  ('actresse', 1),\n",
       "  ('actual', 14),\n",
       "  ('actually', 140),\n",
       "  ('acute', 2),\n",
       "  ('ad', 30),\n",
       "  ('adam', 1),\n",
       "  ('adam_hocksley', 4),\n",
       "  ('add', 31),\n",
       "  ('addict', 1),\n",
       "  ('addicted', 2),\n",
       "  ('addison', 1),\n",
       "  ('addison_blake', 15),\n",
       "  ('addition', 10),\n",
       "  ('additional', 17),\n",
       "  ('additionally', 1),\n",
       "  ('addle', 1),\n",
       "  ('address', 101),\n",
       "  ('adduce', 2),\n",
       "  ('adequate', 1),\n",
       "  ('adequately', 1),\n",
       "  ('adhere', 4),\n",
       "  ('adhering', 1),\n",
       "  ('adirondack', 2),\n",
       "  ('adjacent', 3),\n",
       "  ('adjoin', 6),\n",
       "  ('adjourn', 47),\n",
       "  ('adjournment', 23),\n",
       "  ('adjust', 1),\n",
       "  ('adjuster', 1),\n",
       "  ('administer', 9),\n",
       "  ('administration', 1),\n",
       "  ('administrator', 2),\n",
       "  ('admirable', 1),\n",
       "  ('admirer', 1),\n",
       "  ('admissibility', 1),\n",
       "  ('admissible', 4),\n",
       "  ('admission', 10),\n",
       "  ('admit', 115),\n",
       "  ('admittance', 2),\n",
       "  ('admittedly', 2),\n",
       "  ('admonish', 1),\n",
       "  ('admonition', 1),\n",
       "  ('adopt', 12),\n",
       "  ('adoption', 7),\n",
       "  ('adorable', 2),\n",
       "  ('adore', 1),\n",
       "  ('adrian', 16),\n",
       "  ('adroitly', 1),\n",
       "  ('adult', 1),\n",
       "  ('advance', 26),\n",
       "  ('advanced', 1),\n",
       "  ('advantage', 18),\n",
       "  ('advantageous', 1),\n",
       "  ('adventure', 2),\n",
       "  ('adventurous', 1),\n",
       "  ('adverse', 4),\n",
       "  ('advertise', 2),\n",
       "  ('advertisement', 2),\n",
       "  ('advertiser', 1),\n",
       "  ('advertising', 3),\n",
       "  ('advice', 41),\n",
       "  ('advisable', 1),\n",
       "  ('advise', 32),\n",
       "  ('advisory', 1),\n",
       "  ('aeronautic', 4),\n",
       "  ('afar', 1),\n",
       "  ('affair', 17),\n",
       "  ('affect', 13),\n",
       "  ('affection', 5),\n",
       "  ('affidavit', 2),\n",
       "  ('affirmative', 1),\n",
       "  ('affix', 1),\n",
       "  ('affluent', 1),\n",
       "  ('afford', 11),\n",
       "  ('afield', 3),\n",
       "  ('aforesaid', 1),\n",
       "  ('aforethought', 1),\n",
       "  ('afraid', 183),\n",
       "  ('aftem', 3),\n",
       "  ('afterhe', 1),\n",
       "  ('afternoon', 188),\n",
       "  ('afterward', 1),\n",
       "  ('agatha_alder', 10),\n",
       "  ('age', 26),\n",
       "  ('aged', 1),\n",
       "  ('agency', 17),\n",
       "  ('agenda', 2),\n",
       "  ('agent', 16),\n",
       "  ('aggressive', 1),\n",
       "  ('agitate', 3),\n",
       "  ('agne', 4),\n",
       "  ('agnes', 3),\n",
       "  ('ago', 398),\n",
       "  ('agree', 122),\n",
       "  ('agreeable', 4),\n",
       "  ('agreement', 50),\n",
       "  ('ahead', 95),\n",
       "  ('ahh', 3),\n",
       "  ('ahoy', 1),\n",
       "  ('aid', 15),\n",
       "  ('aide', 1),\n",
       "  ('ailment', 1),\n",
       "  ('aim', 5),\n",
       "  ('aimless', 1),\n",
       "  ('ain', 15),\n",
       "  ('air', 23),\n",
       "  ('aircraft', 4),\n",
       "  ('airfreight', 1),\n",
       "  ('airline', 10),\n",
       "  ('airmail', 1),\n",
       "  ('airplane', 5),\n",
       "  ('airport', 20),\n",
       "  ('airtight', 1),\n",
       "  ('aisle', 1),\n",
       "  ('ajar', 1),\n",
       "  ('ajax', 1),\n",
       "  ('alarm', 34),\n",
       "  ('alaskan', 1),\n",
       "  ('albert', 5),\n",
       "  ('alberto', 1),\n",
       "  ('alcatraz', 1),\n",
       "  ('alcohol', 6),\n",
       "  ('alcoholic', 3),\n",
       "  ('alcorn', 1),\n",
       "  ('alder', 10),\n",
       "  ('alert', 7),\n",
       "  ('algebra', 1),\n",
       "  ('alibi', 10),\n",
       "  ('alike', 10),\n",
       "  ('alimony', 2),\n",
       "  ('alive', 87),\n",
       "  ('allabout', 1),\n",
       "  ('allegation', 4),\n",
       "  ('allege', 10),\n",
       "  ('alleged', 1),\n",
       "  ('allegedly', 4),\n",
       "  ('allentown', 2),\n",
       "  ('allergic', 3),\n",
       "  ('allergy', 1),\n",
       "  ('alley', 1),\n",
       "  ('alliance', 1),\n",
       "  ('alligator', 1),\n",
       "  ('allof', 1),\n",
       "  ('allow', 68),\n",
       "  ('allowable', 1),\n",
       "  ('allowance', 1),\n",
       "  ('allre', 31),\n",
       "  ('allred', 5),\n",
       "  ('allthe', 1),\n",
       "  ('ally', 3),\n",
       "  ('alongside', 1),\n",
       "  ('aloud', 1),\n",
       "  ('alrighty', 2),\n",
       "  ('alter', 11),\n",
       "  ('alteration', 2),\n",
       "  ('altercation', 4),\n",
       "  ('alternate', 1),\n",
       "  ('alternative', 7),\n",
       "  ('altogether', 2),\n",
       "  ('aluminium', 1),\n",
       "  ('aluminum', 3),\n",
       "  ('amair', 5),\n",
       "  ('amass', 1),\n",
       "  ('amateur', 7),\n",
       "  ('amazement', 1),\n",
       "  ('amazing', 8),\n",
       "  ('amazingly', 1),\n",
       "  ('ambition', 3),\n",
       "  ('ambitious', 2),\n",
       "  ('ambulance', 14),\n",
       "  ('ambulatory', 1),\n",
       "  ('amect', 6),\n",
       "  ('amecte', 1),\n",
       "  ('amection', 1),\n",
       "  ('amelia', 2),\n",
       "  ('amelia_corne', 1),\n",
       "  ('amelia_corning', 6),\n",
       "  ('amend', 1),\n",
       "  ('amendment', 2),\n",
       "  ('amenity', 2),\n",
       "  ('american', 8),\n",
       "  ('amicable', 1),\n",
       "  ('amicably', 1),\n",
       "  ('amiliate', 1),\n",
       "  ('ammonia', 4),\n",
       "  ('ammunition', 1),\n",
       "  ('amord', 5),\n",
       "  ('amorde', 1),\n",
       "  ('amorous', 1),\n",
       "  ('amos_martin', 5),\n",
       "  ('amount', 3),\n",
       "  ('ample', 5),\n",
       "  ('amplifier', 1),\n",
       "  ('amul', 5),\n",
       "  ('amully', 6),\n",
       "  ('amuse', 4),\n",
       "  ('amusing', 4),\n",
       "  ('analyse', 1),\n",
       "  ('analysis', 26),\n",
       "  ('analyst', 2),\n",
       "  ('analytical', 1),\n",
       "  ('analyze', 4),\n",
       "  ('anarchist', 1),\n",
       "  ('ancestry', 1),\n",
       "  ('ancy', 1),\n",
       "  ('andafter', 1),\n",
       "  ('andhow', 1),\n",
       "  ('andiwant', 1),\n",
       "  ('andnothe', 1),\n",
       "  ('andrei', 3),\n",
       "  ('andrews', 1),\n",
       "  ('andthing', 1),\n",
       "  ('andy', 1),\n",
       "  ('angel', 10),\n",
       "  ('angela', 1),\n",
       "  ('anger', 4),\n",
       "  ('angle', 7),\n",
       "  ('angrily', 1),\n",
       "  ('angry', 30),\n",
       "  ('animal', 12),\n",
       "  ('anita', 3),\n",
       "  ('ankle', 2),\n",
       "  ('anniversary', 4),\n",
       "  ('annotate', 1),\n",
       "  ('announce', 16),\n",
       "  ('announcement', 5),\n",
       "  ('announcer', 3),\n",
       "  ('annoy', 6),\n",
       "  ('annoyed', 1),\n",
       "  ('annoying', 1),\n",
       "  ('annual', 2),\n",
       "  ('annuity', 1),\n",
       "  ('annul', 4),\n",
       "  ('annulment', 6),\n",
       "  ('anodyne', 1),\n",
       "  ('anonymous', 28),\n",
       "  ('anonymously', 4),\n",
       "  ('answer', 361),\n",
       "  ('answerable', 1),\n",
       "  ('answering', 1),\n",
       "  ('antagonistic', 1),\n",
       "  ('anticipate', 17),\n",
       "  ('anticlimax', 1),\n",
       "  ('antihistaminic', 1),\n",
       "  ('antique', 3),\n",
       "  ('antonio', 1),\n",
       "  ('anxiety', 3),\n",
       "  ('anxious', 21),\n",
       "  ('anymore', 40),\n",
       "  ('anyplace', 5),\n",
       "  ('anytime', 9),\n",
       "  ('anywhereland', 2),\n",
       "  ('apart', 19),\n",
       "  ('apartment', 499),\n",
       "  ('ape', 2),\n",
       "  ('apex', 2),\n",
       "  ('apiece', 2),\n",
       "  ('apologetic', 1),\n",
       "  ('apologise', 6),\n",
       "  ('apologize', 8),\n",
       "  ('apologizing', 1),\n",
       "  ('apology', 4),\n",
       "  ('apparent', 15),\n",
       "  ('apparently', 92),\n",
       "  ('appeal', 5),\n",
       "  ('appear', 76),\n",
       "  ('appearance', 13),\n",
       "  ('appeared', 1),\n",
       "  ('appetite', 1),\n",
       "  ('applause', 3),\n",
       "  ('apple', 4),\n",
       "  ('apply', 12),\n",
       "  ('appoint', 14),\n",
       "  ('appointment', 42),\n",
       "  ('appraisal', 10),\n",
       "  ('appraise', 7),\n",
       "  ('appraiser', 8),\n",
       "  ('appreciable', 1),\n",
       "  ('appreciate', 55),\n",
       "  ('apprehend', 3),\n",
       "  ('apprise', 1),\n",
       "  ('approach', 47),\n",
       "  ('appropriate', 1),\n",
       "  ('approval', 3),\n",
       "  ('approve', 16),\n",
       "  ('approximate', 4),\n",
       "  ('approximately', 56),\n",
       "  ('aquarium', 1),\n",
       "  ('arbitrary', 6),\n",
       "  ('arch', 1),\n",
       "  ('archaeologist', 1),\n",
       "  ('archer', 3),\n",
       "  ('arcus', 1),\n",
       "  ('ard', 6),\n",
       "  ('arde', 2),\n",
       "  ('arding', 1),\n",
       "  ('area', 34),\n",
       "  ('aregoe', 1),\n",
       "  ('arelooke', 1),\n",
       "  ('aren', 39),\n",
       "  ('areyou', 1),\n",
       "  ('argue', 14),\n",
       "  ('arguing', 3),\n",
       "  ('argument', 32),\n",
       "  ('argumentative', 11),\n",
       "  ('argyle', 1),\n",
       "  ('arise', 7),\n",
       "  ('arlene', 7),\n",
       "  ('arlene_dowle', 2),\n",
       "  ('arlene_dowling', 8),\n",
       "  ('arm', 59),\n",
       "  ('armed', 4),\n",
       "  ('armitage', 3),\n",
       "  ('armor', 2),\n",
       "  ('armored', 1),\n",
       "  ('armour', 1),\n",
       "  ('armoured', 2),\n",
       "  ('army', 3),\n",
       "  ('arnie', 2),\n",
       "  ('arnold', 1),\n",
       "  ('arouse', 1),\n",
       "  ('arraign', 3),\n",
       "  ('arraignment', 2),\n",
       "  ('arrange', 51),\n",
       "  ('arrangement', 38),\n",
       "  ('arrest', 91),\n",
       "  ('arrival', 6),\n",
       "  ('arrive', 141),\n",
       "  ('arrived', 1),\n",
       "  ('arrogance', 1),\n",
       "  ('arrogant', 1),\n",
       "  ('arrow', 1),\n",
       "  ('arsenic', 36),\n",
       "  ('arson', 3),\n",
       "  ('arsonist', 1),\n",
       "  ('art', 28),\n",
       "  ('artery', 1),\n",
       "  ('arthritis', 5),\n",
       "  ('article', 22),\n",
       "  ('artie', 5),\n",
       "  ('artifact', 1),\n",
       "  ('artist', 18),\n",
       "  ('artistic', 1),\n",
       "  ('artistically', 1),\n",
       "  ('ascend', 1),\n",
       "  ('ascertain', 1),\n",
       "  ('ash', 1),\n",
       "  ('ashamed', 18),\n",
       "  ('ashe', 2),\n",
       "  ('ashore', 7),\n",
       "  ('ashtray', 5),\n",
       "  ('aside', 15),\n",
       "  ('ask', 866),\n",
       "  ('askin', 1),\n",
       "  ('asking', 1),\n",
       "  ('askyou', 1),\n",
       "  ('asleep', 34),\n",
       "  ('aspect', 8),\n",
       "  ('aspire', 1),\n",
       "  ('aspirin', 1),\n",
       "  ('assailant', 3),\n",
       "  ('assault', 14),\n",
       "  ('assemble', 6),\n",
       "  ('assembled', 1),\n",
       "  ('assert', 1),\n",
       "  ('assertion', 1),\n",
       "  ('assess', 1),\n",
       "  ('asset', 19),\n",
       "  ('assign', 11),\n",
       "  ('assignation', 1),\n",
       "  ('assignment', 6),\n",
       "  ('assist', 2),\n",
       "  ('assistance', 9),\n",
       "  ('assistant', 8),\n",
       "  ('associate', 13),\n",
       "  ('association', 1),\n",
       "  ('assortment', 1),\n",
       "  ('assume', 107),\n",
       "  ('assumed', 1),\n",
       "  ('assumption', 6),\n",
       "  ('assurance', 10),\n",
       "  ('assure', 23),\n",
       "  ('assured', 1),\n",
       "  ('assuredly', 1),\n",
       "  ('asthma', 1),\n",
       "  ('astonish', 2),\n",
       "  ('astronaut', 5),\n",
       "  ('atmosphere', 1),\n",
       "  ('attach', 10),\n",
       "  ('attached', 1),\n",
       "  ('attachment', 7),\n",
       "  ('attack', 39),\n",
       "  ('attain', 1),\n",
       "  ('attempt', 54),\n",
       "  ('attend', 16),\n",
       "  ('attendance', 1),\n",
       "  ('attendant', 11),\n",
       "  ('atteniion', 1),\n",
       "  ('attention', 48),\n",
       "  ('attest', 1),\n",
       "  ('attire', 1),\n",
       "  ('attitude', 8),\n",
       "  ('attorney', 128),\n",
       "  ('attract', 3),\n",
       "  ('attraction', 1),\n",
       "  ('attractive', 13),\n",
       "  ('attribute', 1),\n",
       "  ('auburn', 1),\n",
       "  ('auction', 3),\n",
       "  ('audible', 4),\n",
       "  ('audience', 11),\n",
       "  ('audit', 5),\n",
       "  ('auditor', 5),\n",
       "  ('audits', 1),\n",
       "  ('august_dalgran', 15),\n",
       "  ('aunt', 14),\n",
       "  ('aunt_wilma', 2),\n",
       "  ('austere', 1),\n",
       "  ('austin_cullen', 19),\n",
       "  ('authentic', 9),\n",
       "  ('authenticate', 3),\n",
       "  ('authenticating', 2),\n",
       "  ('authentication', 7),\n",
       "  ('authenticity', 6),\n",
       "  ('author', 2),\n",
       "  ('authorisation', 1),\n",
       "  ('authorise', 4),\n",
       "  ('authoritative', 1),\n",
       "  ('authority', 49),\n",
       "  ('authorization', 5),\n",
       "  ('authorize', 14),\n",
       "  ('authorship', 2),\n",
       "  ('auto', 6),\n",
       "  ('autograph', 1),\n",
       "  ('automatic', 14),\n",
       "  ('automatically', 5),\n",
       "  ('automobile', 8),\n",
       "  ('automobile_accident', 10),\n",
       "  ('autonomy', 1),\n",
       "  ('autopsy', 43),\n",
       "  ('avail', 2),\n",
       "  ('available', 21),\n",
       "  ('avenue', 2),\n",
       "  ('average', 13),\n",
       "  ('aversion', 1),\n",
       "  ('aviation', 1),\n",
       "  ('avoid', 30),\n",
       "  ('await', 1),\n",
       "  ('awake', 10),\n",
       "  ('awaken', 7),\n",
       "  ('award', 1),\n",
       "  ('aware', 64),\n",
       "  ('away', 393),\n",
       "  ('awful', 15),\n",
       "  ('awfully', 17),\n",
       "  ('awhile', 1),\n",
       "  ('awk', 5),\n",
       "  ('awkward', 4),\n",
       "  ('ax', 2),\n",
       "  ('axe', 1),\n",
       "  ('ay', 1),\n",
       "  ('aye', 3),\n",
       "  ('babble', 2),\n",
       "  ('baby', 134),\n",
       "  ('babysit', 2),\n",
       "  ('babysitter', 2),\n",
       "  ('bac_ard', 1),\n",
       "  ('bachelor', 6),\n",
       "  ('back', 9),\n",
       "  ('backbone', 1),\n",
       "  ('backer', 1),\n",
       "  ('backfire', 1),\n",
       "  ('backfiring', 2),\n",
       "  ('background', 22),\n",
       "  ('backing', 1),\n",
       "  ('backlash', 2),\n",
       "  ('backstage', 4),\n",
       "  ('backstretch', 1),\n",
       "  ('backtrack', 2),\n",
       "  ('backtracked', 1),\n",
       "  ('backward', 1),\n",
       "  ('backwards', 1),\n",
       "  ('bacmire', 1),\n",
       "  ('bacon', 3),\n",
       "  ('bacteria', 1),\n",
       "  ('bad', 168),\n",
       "  ('bade', 1),\n",
       "  ('badge', 3),\n",
       "  ('badger', 2),\n",
       "  ('badgering', 1),\n",
       "  ('badly', 40),\n",
       "  ('badness', 1),\n",
       "  ('bag', 48),\n",
       "  ('bagby', 1),\n",
       "  ('baggage', 6),\n",
       "  ('bail', 17),\n",
       "  ('bailiff', 15),\n",
       "  ('bain', 11),\n",
       "  ('bait', 3),\n",
       "  ('baited', 1),\n",
       "  ('bake', 2),\n",
       "  ('bakersfield', 2),\n",
       "  ('bakerstown', 3),\n",
       "  ('balance', 14),\n",
       "  ('bald', 1),\n",
       "  ('balfour', 12),\n",
       "  ('ball', 12),\n",
       "  ('ballard', 1),\n",
       "  ('ballistic', 24),\n",
       "  ('ballistically', 3),\n",
       "  ('ballpoint', 1),\n",
       "  ('ballroom', 15),\n",
       "  ('bamboozle', 1),\n",
       "  ('band', 1),\n",
       "  ('bandage', 5),\n",
       "  ('bang', 26),\n",
       "  ('banging', 1),\n",
       "  ('bank', 72),\n",
       "  ('bankbook', 1),\n",
       "  ('banker', 4),\n",
       "  ('banking', 1),\n",
       "  ('bankrupt', 6),\n",
       "  ('bankruptcy', 1),\n",
       "  ('banner', 1),\n",
       "  ('bannion', 21),\n",
       "  ('bannister', 19),\n",
       "  ('bar', 40),\n",
       "  ('barbecue', 5),\n",
       "  ('barbeque', 1),\n",
       "  ('barbiturate', 2),\n",
       "  ('bare', 1),\n",
       "  ('barely', 11),\n",
       "  ('bargain', 9),\n",
       "  ('bargaining', 1),\n",
       "  ('bark', 18),\n",
       "  ('barker', 4),\n",
       "  ('barking', 2),\n",
       "  ('barley', 1),\n",
       "  ('barlow', 6),\n",
       "  ('barne', 14),\n",
       "  ('barrel', 11),\n",
       "  ('barricaded', 1),\n",
       "  ('barrier', 1),\n",
       "  ('barroom', 2),\n",
       "  ('bartender', 4),\n",
       "  ('barter', 1),\n",
       "  ('bascomb', 1),\n",
       "  ('base', 38),\n",
       "  ('baseball', 2),\n",
       "  ('basement', 9),\n",
       "  ('bash', 6),\n",
       "  ('basic', 7),\n",
       "  ('basically', 3),\n",
       "  ('basis', 27),\n",
       "  ('basket', 3),\n",
       "  ('bass', 1),\n",
       "  ('bat', 4),\n",
       "  ('batch', 6),\n",
       "  ('bate', 1),\n",
       "  ('bates', 1),\n",
       "  ('bath', 4),\n",
       "  ('bathrobe', 1),\n",
       "  ('bathroom', 13),\n",
       "  ('bathtub', 1),\n",
       "  ('batter', 1),\n",
       "  ('battery', 2),\n",
       "  ('battle', 4),\n",
       "  ('battleship', 1),\n",
       "  ('bauble', 1),\n",
       "  ('baylor', 3),\n",
       "  ('beach', 21),\n",
       "  ('beam', 1),\n",
       "  ('bean', 3),\n",
       "  ('bear', 55),\n",
       "  ('beard', 3),\n",
       "  ('bearded', 1),\n",
       "  ('bearing', 7),\n",
       "  ('beasely', 5),\n",
       "  ('beat', 37),\n",
       "  ('beating', 1),\n",
       "  ('beatnik', 1),\n",
       "  ('beaton', 3),\n",
       "  ('beaumont', 2),\n",
       "  ('beautiful', 61),\n",
       "  ('beautifully', 4),\n",
       "  ('beauty', 18),\n",
       "  ('beaver', 1),\n",
       "  ('beckmeyer', 2),\n",
       "  ('bed', 65),\n",
       "  ('bedclothe', 1),\n",
       "  ('bedevil', 1),\n",
       "  ('bedroom', 53),\n",
       "  ('bedside', 1),\n",
       "  ('bedtime', 1),\n",
       "  ('beecham', 1),\n",
       "  ('beer', 5),\n",
       "  ('beet', 1),\n",
       "  ('beetle', 2),\n",
       "  ('beg', 11),\n",
       "  ('begged', 1),\n",
       "  ('begin', 72),\n",
       "  ('beginning', 8),\n",
       "  ('behalf', 7),\n",
       "  ('behave', 7),\n",
       "  ('behavior', 6),\n",
       "  ('behaviour', 3),\n",
       "  ('beige', 2),\n",
       "  ('being', 2),\n",
       "  ('belan', 1),\n",
       "  ('belate', 1),\n",
       "  ('belief', 8),\n",
       "  ('believe', 356),\n",
       "  ('bell', 1),\n",
       "  ('bell_ding', 3),\n",
       "  ('bellboy', 1),\n",
       "  ('bellow', 1),\n",
       "  ('belly', 4),\n",
       "  ('belong', 112),\n",
       "  ('belonging', 7),\n",
       "  ('belt', 8),\n",
       "  ('belvedere', 1),\n",
       "  ('bench', 13),\n",
       "  ('bend', 3),\n",
       "  ('bender', 2),\n",
       "  ('benedict', 2),\n",
       "  ('benefactor', 1),\n",
       "  ('beneficent', 1),\n",
       "  ('beneficiary', 2),\n",
       "  ('benefit', 11),\n",
       "  ('bent', 5),\n",
       "  ('benzidine', 2),\n",
       "  ('bequeath', 1),\n",
       "  ('bequest', 2),\n",
       "  ('bereave', 2),\n",
       "  ('beretta', 1),\n",
       "  ('berry', 1),\n",
       "  ('bert', 1),\n",
       "  ('berth', 1),\n",
       "  ('besomethe', 1),\n",
       "  ('best', 25),\n",
       "  ('bet', 54),\n",
       "  ('betray', 10),\n",
       "  ('better', 242),\n",
       "  ('betty', 1),\n",
       "  ('beverage', 2),\n",
       "  ('beverly_hill', 16),\n",
       "  ('bias', 8),\n",
       "  ('biased', 1),\n",
       "  ('bible', 3),\n",
       "  ('biblical', 1),\n",
       "  ('bid', 20),\n",
       "  ('bidder', 9),\n",
       "  ('bidding', 2),\n",
       "  ('big', 189),\n",
       "  ('bigamous', 1),\n",
       "  ('bigamy', 5),\n",
       "  ('bike', 1),\n",
       "  ('bikini', 2),\n",
       "  ('bill', 123),\n",
       "  ('billing', 2),\n",
       "  ('biltmore', 1),\n",
       "  ('bind', 39),\n",
       "  ('bingo', 1),\n",
       "  ('binney', 4),\n",
       "  ('binocular', 3),\n",
       "  ('bird', 20),\n",
       "  ('birth', 9),\n",
       "  ('birth_certificate', 2),\n",
       "  ('birthday', 10),\n",
       "  ('birthright', 2),\n",
       "  ('biscayne', 1),\n",
       "  ('bishop', 2),\n",
       "  ('bishop_mallory', 8),\n",
       "  ('bit', 70),\n",
       "  ('bite', 6),\n",
       "  ('bitter', 1),\n",
       "  ('bitterness', 3),\n",
       "  ('blab', 2),\n",
       "  ('blabbermouth', 3),\n",
       "  ('black', 37),\n",
       "  ('blacklist', 1),\n",
       "  ('blackmail', 104),\n",
       "  ('blackmailed', 3),\n",
       "  ('blackmailer', 8),\n",
       "  ('blackmailing', 1),\n",
       "  ('blackout', 2),\n",
       "  ('blade', 3),\n",
       "  ('blake', 28),\n",
       "  ('blame', 41),\n",
       "  ('blane', 1),\n",
       "  ('blank', 17),\n",
       "  ('blanket', 3),\n",
       "  ('blare', 1),\n",
       "  ('blast', 1),\n",
       "  ('blatantly', 1),\n",
       "  ('blaze', 1),\n",
       "  ('bleak', 3),\n",
       "  ('blee', 3),\n",
       "  ('bleed', 12),\n",
       "  ('bleeding', 1),\n",
       "  ('bless', 3),\n",
       "  ('blessing', 3),\n",
       "  ('blind', 13),\n",
       "  ('blindfold', 1),\n",
       "  ('blissfully', 1),\n",
       "  ('block', 29),\n",
       "  ('blockbuster', 1),\n",
       "  ('blond', 26),\n",
       "  ('blonde', 1),\n",
       "  ('blood', 92),\n",
       "  ('bloodstain', 10),\n",
       "  ('bloodstaine', 1),\n",
       "  ('bloodstream', 1),\n",
       "  ('bloody', 2),\n",
       "  ('bloom', 2),\n",
       "  ('blotter', 1),\n",
       "  ('blouse', 1),\n",
       "  ('blow', 72),\n",
       "  ('blowup', 1),\n",
       "  ('bludgeon', 1),\n",
       "  ('blue', 27),\n",
       "  ('bluebeard', 1),\n",
       "  ('blueprint', 2),\n",
       "  ('bluff', 7),\n",
       "  ('blum', 5),\n",
       "  ('blume', 2),\n",
       "  ('blunder', 1),\n",
       "  ('blunt_instrument', 6),\n",
       "  ('bluntly', 2),\n",
       "  ('blurted', 1),\n",
       "  ('board', 29),\n",
       "  ('boardinghouse', 1),\n",
       "  ('boat', 68),\n",
       "  ('bob', 1),\n",
       "  ('bodily', 1),\n",
       "  ('body', 348),\n",
       "  ('boff', 1),\n",
       "  ('boil', 8),\n",
       "  ('boiling', 1),\n",
       "  ('bold', 1),\n",
       "  ('boldly', 1),\n",
       "  ('bole', 23),\n",
       "  ('bolt', 2),\n",
       "  ('bomb', 4),\n",
       "  ('bon', 1),\n",
       "  ('bond', 21),\n",
       "  ('bonding', 1),\n",
       "  ('bondsman', 1),\n",
       "  ('bone', 12),\n",
       "  ('bonfire', 2),\n",
       "  ('bonsal', 5),\n",
       "  ('bonus', 4),\n",
       "  ('bood', 1),\n",
       "  ('book', 177),\n",
       "  ('bookend', 15),\n",
       "  ('bookie', 2),\n",
       "  ('booking', 1),\n",
       "  ('bookkeeper', 7),\n",
       "  ('bookmake', 2),\n",
       "  ('bookmaking', 2),\n",
       "  ('bookstore', 5),\n",
       "  ('boom', 3),\n",
       "  ('boost', 3),\n",
       "  ('boot', 4),\n",
       "  ('booth', 9),\n",
       "  ('booze', 3),\n",
       "  ('borden', 10),\n",
       "  ('border', 5),\n",
       "  ('bore', 5),\n",
       "  ('bored', 3),\n",
       "  ('borrow', 41),\n",
       "  ('borrowing', 1),\n",
       "  ('bosom', 1),\n",
       "  ('boss', 35),\n",
       "  ('botched', 1),\n",
       "  ('bother', 39),\n",
       "  ('bothering', 3),\n",
       "  ('bottle', 100),\n",
       "  ('bounce', 4),\n",
       "  ('bouncer', 1),\n",
       "  ('bouquet', 1),\n",
       "  ('bow', 3),\n",
       "  ('bower', 1),\n",
       "  ('bowl', 2),\n",
       "  ('box', 72),\n",
       "  ('boxed', 1),\n",
       "  ('boy', 207),\n",
       "  ('boyfriend', 18),\n",
       "  ('boykin', 1),\n",
       "  ('boysover', 1),\n",
       "  ('brace', 5),\n",
       "  ('bracelet', 3),\n",
       "  ('brad', 2),\n",
       "  ('brad_shelby', 17),\n",
       "  ('bradford', 3),\n",
       "  ('brag', 3),\n",
       "  ('brain', 39),\n",
       "  ('brainpan', 1),\n",
       "  ('brainstorm', 1),\n",
       "  ('brake', 20),\n",
       "  ('branch', 4),\n",
       "  ('brand', 55),\n",
       "  ('brander', 2),\n",
       "  ('brander_harri', 4),\n",
       "  ('brander_harris', 1),\n",
       "  ('brass', 7),\n",
       "  ('brasso', 1),\n",
       "  ('brat', 1),\n",
       "  ('brave', 1),\n",
       "  ('bread', 2),\n",
       "  ('breadth', 1),\n",
       "  ('break', 149),\n",
       "  ('breakdown', 5),\n",
       "  ('breaker', 1),\n",
       "  ('breakfast', 9),\n",
       "  ('breaking', 4),\n",
       "  ('breamast', 2),\n",
       "  ('breast', 1),\n",
       "  ('breath', 4),\n",
       "  ('breathe', 2),\n",
       "  ('breathing', 4),\n",
       "  ('breathing_heavily', 2),\n",
       "  ('breed', 2),\n",
       "  ('breel', 24),\n",
       "  ('bren', 1),\n",
       "  ('brent', 19),\n",
       "  ('brentwood', 2),\n",
       "  ('brewer', 1),\n",
       "  ('brewster', 22),\n",
       "  ('bribe', 11),\n",
       "  ('bribery', 4),\n",
       "  ('brice', 1),\n",
       "  ('brick', 2),\n",
       "  ('bridal', 1),\n",
       "  ('bride', 4),\n",
       "  ('bridge', 2),\n",
       "  ('bridle', 1),\n",
       "  ('brie', 1),\n",
       "  ('brief', 12),\n",
       "  ('briefcase', 9),\n",
       "  ('briefly', 5),\n",
       "  ('briefs', 1),\n",
       "  ('briggs', 2),\n",
       "  ('bright', 22),\n",
       "  ('bright_magic', 16),\n",
       "  ('brighten', 1),\n",
       "  ('brightness', 1),\n",
       "  ('brighton', 1),\n",
       "  ('brilliant', 5),\n",
       "  ('brimstone', 1),\n",
       "  ('brine', 1),\n",
       "  ('bring', 300),\n",
       "  ('british', 1),\n",
       "  ('broad', 2),\n",
       "  ('broadcast', 2),\n",
       "  ('broadway', 1),\n",
       "  ('brok', 1),\n",
       "  ('broke', 1),\n",
       "  ('broken', 12),\n",
       "  ('broker', 5),\n",
       "  ('bronze', 2),\n",
       "  ('brooch', 1),\n",
       "  ('brood', 1),\n",
       "  ('brook', 2),\n",
       "  ('brookline', 1),\n",
       "  ('broom', 1),\n",
       "  ('brother', 152),\n",
       "  ('brown', 3),\n",
       "  ('brownish', 1),\n",
       "  ('browser', 1),\n",
       "  ('bruce', 1),\n",
       "  ('bruise', 23),\n",
       "  ('bruner', 3),\n",
       "  ('brunette', 10),\n",
       "  ('brush', 5),\n",
       "  ('brushwork', 1),\n",
       "  ('bryant_hallsy', 4),\n",
       "  ('bubble', 2),\n",
       "  ('bubbly', 1),\n",
       "  ('buck', 30),\n",
       "  ('bucket', 1),\n",
       "  ('buckman', 3),\n",
       "  ('buddy', 4),\n",
       "  ('budge', 1),\n",
       "  ('budget', 4),\n",
       "  ('bug', 2),\n",
       "  ('bugler', 1),\n",
       "  ('buick', 1),\n",
       "  ('build', 49),\n",
       "  ('building', 37),\n",
       "  ('buildup', 1),\n",
       "  ('bulb', 1),\n",
       "  ('bulbs', 1),\n",
       "  ('bulk', 2),\n",
       "  ('bulkhead', 1),\n",
       "  ('bulky', 5),\n",
       "  ('bull', 2),\n",
       "  ('bullet', 146),\n",
       "  ('bulletin', 11),\n",
       "  ('bullion', 1),\n",
       "  ('bully', 1),\n",
       "  ('bumaloe', 1),\n",
       "  ('bummed', 1),\n",
       "  ('bump', 11),\n",
       "  ('bumper', 2),\n",
       "  ('bunch', 3),\n",
       "  ('bundle', 5),\n",
       "  ('bung', 1),\n",
       "  ('bungalow', 34),\n",
       "  ...]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=5, \n",
    "                                           random_state=412,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=5,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.025*\"know\" + 0.020*\"go\" + 0.017*\"get\" + 0.013*\"want\" + 0.012*\"come\" + '\n",
      "  '0.012*\"think\" + 0.011*\"look\" + 0.011*\"right\" + 0.010*\"good\" + 0.009*\"tell\"'),\n",
      " (1,\n",
      "  '0.014*\"soul\" + 0.008*\"time\" + 0.008*\"let\" + 0.008*\"come\" + 0.008*\"way\" + '\n",
      "  '0.008*\"go\" + 0.008*\"right\" + 0.007*\"want\" + 0.006*\"know\" + 0.006*\"think\"'),\n",
      " (2,\n",
      "  '0.015*\"know\" + 0.012*\"tell\" + 0.011*\"go\" + 0.010*\"come\" + 0.010*\"think\" + '\n",
      "  '0.009*\"get\" + 0.009*\"want\" + 0.009*\"find\" + 0.009*\"right\" + 0.008*\"thank\"'),\n",
      " (3,\n",
      "  '0.000*\"know\" + 0.000*\"go\" + 0.000*\"get\" + 0.000*\"right\" + 0.000*\"come\" + '\n",
      "  '0.000*\"want\" + 0.000*\"tell\" + 0.000*\"time\" + 0.000*\"look\" + 0.000*\"say\"'),\n",
      " (4,\n",
      "  '0.000*\"know\" + 0.000*\"go\" + 0.000*\"think\" + 0.000*\"get\" + 0.000*\"tell\" + '\n",
      "  '0.000*\"come\" + 0.000*\"say\" + 0.000*\"right\" + 0.000*\"time\" + 0.000*\"want\"')]\n"
     ]
    }
   ],
   "source": [
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -7.3622517770415365\n"
     ]
    }
   ],
   "source": [
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.25962260241889445\n"
     ]
    }
   ],
   "source": [
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=test_df[\"text_lemmatized\"], dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
